\documentclass[11pt,a4paper]{article}

\usepackage{../jedusor}	

\renewcommand{\headrulewidth}{0pt} 
\renewcommand{\footrulewidth}{1pt}
\fancyhead[C]{}
\fancyhead[L]{}
\fancyhead[R]{}
\fancyfoot[C]{\thepage} 
\fancyfoot[L]{Sacha Ben-Arous}
\fancyfoot[R]{E.N.S Paris-Saclay}
	
\begin{document}
\newpage
\begin{center}
\section*{Théorie de la mesure} 
\end{center}

\subsection*{Contexte et méthode}

\begin{itemize}
\item[-] Toujours se demander : dans quel ensemble je travaille, quelle est la tribu, quelle est la mesure ? 
\item[-] Utiliser la régularité des mesures, les raisonnements par densité : \\
 Indicatrices $\rightarrow$ fonctions étagées $\rightarrow$ positives (limite croissante) $\rightarrow$ mesurables (parties positive/négative). 
\item[-] User et abuser des $\limsup$ et $\liminf$.
\end{itemize}

\subsection*{Motivations}
Le problème de l'intégrale de Riemann est que la propriété de Riemann-intégrabilité n'est pas stable par limite simple, ce qui pose donc problème pour établir des théorèmes de limite intégrale généraux. De plus, même si l'on se restreint à une situation ne comportant que des fonctions continues (par morceaux), la preuve est très pénible.  Une illustration concrète de ce phénomène est le résultat suivant :
\begin{mthm}{}
Soit $f:[a,b] \mapsto \R$ une fonction bornée. Alors $f$ est Riemann-intégrable si et seulement si l'ensemble de ses points de discontinuité est négligeable.
\end{mthm}
\noindent où l'on peut définir la notion de négligeabilité sans avoir recours à la théorie de la mesure :
\begin{definstar}
Une partie $A$ de $\R$ est négligeable si pour tout $\varepsilon > 0$, il existe une famille d'intervalles $(I_i)_{i\in \N}$ telle que $A\subset \bigcup_{i\in \N} I_i$ et $\displaystyle \sum_{i\in \N} l(I_i) \leq \varepsilon$, où $l(I_i)$ est la longueur de l'intervalle $I_i$.
\end{definstar}
Le prototype de fonction non intégrable au sens de Riemann est la fonction indicatrice des rationnels, qui bien que limite simple de fonctions en escalier, n'est pas Riemann-intégrable d'après le théorème précédent. Historiquement, ce furent plutôt les travaux de Fourier sur l'équation de la chaleur qui motivèrent le développement de la théorie de la mesure afin de rendre rigoureuses les manipulations du noyau de la chaleur. \\

Ainsi, il a fallu changer de méthode d'intégration, en intégrant par tranches rectangulaires horizontales, dont la base peut alors être un ensemble plus complexe qu'un simple intervalle. La limite simple de fonctions mesurables sera alors mesurable, mais on sera attentif aux subtilités induites par la convergence presque partout, qui sont discrètement évacuées grâce à la notion de complétion d'une tribu, qui permet justement de rendre mesurables les ensembles négligeables.

\subsection*{Définitions}

\subsection*{Résultats principaux}
Dans tout ce qui suit, on travaille dans un espace mesuré $(E,\mathcal{A},\mu)$, et on pourra utiliser un espace métrique $(T,d)$.


\begin{thmstar}[Dynkin] 
Le $\sigma$-système engendré par un $\pi$-système est égal à la tribu engendrée par ce dernier.
\end{thmstar}


\begin{thmstar}[Convergence monotone]
Soit $(f_n)_{n\in\N}$ une suite de fonctions mesurables de $E$ dans $[0,+\infty]$, telle que pour tout $n\geq 0$, $f_n \leq f_{n+1}  $. Alors, en notant $f$ la limite simple de cette suite, on a que $f$ est mesurable, et : 
\[\int f = \lim\limits_{n \to +\infty} \int f_n \]
\end{thmstar}


\begin{thmstar}[Convergence dominée]
Soit $(f_n)_{n\in\N}$ une suite de fonctions mesurables qui converge simplement vers $f$. Si il existe $g$ intégrable telle que pour tout $n \geq 0$, $\left| f_n \right| \leq g$, alors $f$ est intégrable et :
\[\int f = \lim\limits_{n \to +\infty} \int f_n \]
\end{thmstar}


\begin{rmq}
On peut seulement supposer les conditions ci-dessus vraies presque partout, mais dans ce cas il faut imposer la mesurabilité de la limite simple, ou bien travailler dans la tribu complétée, comme l'explique la remarque suivante.
\end{rmq}


\begin{rmq}
Si $\tilde{f} : E \mapsto F$ est presque partout égale à une fonction mesurable $f : (E,\mathcal{A},\mu) \mapsto (F,\mathcal{B})$, alors $\tilde{f}$ est mesurable pour la tribu complétée $\overline{\mathcal{A}}$ de $\mu$ sur $E$.
\end{rmq}

\begin{thmstar}[Régularité des mesures boréliennes finies]
Si $\mu$ est une mesure borélienne finie sur un espace métrique $(T,d)$, alors $\mu$ est régulière, i.e pour tout $A \in \mathcal{B}(T)$:
\begin{align*}
\mu(A) &= \inf \left\{ \mu(U) \ \setbar \ U \text{ ouvert},\  A \subset U \right\} \\
&=\sup \left\{ \mu(F) \ \setbar \ F \text{ fermé}, \ F \subset A \right\}
\end{align*}
\end{thmstar}


\begin{rmq}
Dans un espace polonais (métrique séparable complet), on a de plus que la régularité intérieure est sur les compacts.
\end{rmq}

\begin{thmstar}[Régularité des mesures de Radon]
Si $\mu$ est une mesure de Radon sur un espace métrique localement compact séparable (ex. $\R^d$), alors $\mu$ est régulière, et  la régularité intérieure est sur les compacts. 
\end{thmstar}

\begin{thmstar}[Représentation de Riesz-Markov]
Si $E$ est un espace métrique localement compact séparable, et $\Lambda : C_c(E) \mapsto \R$ une forme linéaire positive, alors il existe une unique mesure de Radon $\mu$ sur $E$ telle que, pour tout $f\in C_c(E)$ : 
\[\Lambda(f) = \int f \mathrm{d}\mu\]
\end{thmstar}

\begin{rmq}
Avec ce qui précède, on obtient de plus que la mesure $\mu$ est régulière.
\end{rmq}

\begin{thmstar}[Inégalités d'Hölder et de Young]
Soient $ 1 \leq p,q,r \leq +\infty$, $f\in L^p$, $g \in L^q$, on a les inégalités :
\begin{itemize}
\item[•] Si $p$ et $q$ sont des exposants conjugués, i.e : $\frac{1}{p} + \frac{1}{q} = 1$, alors $\|fg\|_{L^1} \leq \|f\|_{L^p}\|g\|_{L^q}$.
\item[•] Si $\frac{1}{p} + \frac{1}{q} = 1 + \frac{1}{r}$, alors $\|f*g\|_{L^r} \leq \|f\|_{L^p}\|g\|_{L^q}$.
\end{itemize}
\end{thmstar}

\begin{thmstar}[Riesz-Fischer]
Si $p \in [1; +\infty]$, alors $L^p(E,\mathcal{A},\mu)$ est un espace de Banach.
\end{thmstar}


\begin{rmq}
La preuve du théorème ci-dessus donne en particulier que la convergence en norme $L^p$ implique l'existence d'une extraite qui converge presque partout. Le théorème de convergence dominée fournit une sorte de réciproque, i.e que la convergence presque partout entraine la convergence $L^p$, sous réserve d'avoir une domination intégrable.
\end{rmq}

\begin{thmstar}[Densité]
Soit $p \in [1;+\infty[$.
\begin{enumerate}
\item Les fonctions étagées sont denses dans $L^p$. De plus, si $\mathcal{A}$ est généré par une famille dénombrable dense et si $\mu$ est $\sigma$-finie, alors $L^p(E,\mathcal{A}, \mu)$ est séparable.
\item 
\begin{enumerate}
\item Si $(E,d)$ est un espace métrique et $\mu$ une mesure borélienne finie, alors les fonctions lipschitziennes sont denses dans $L^p$.
\item Si de plus $(E,d)$ est localement compact séparable et $\mu$ est une mesure de Radon, alors les fonctions lipschitziennes à support compact sont denses dans $L^p$.
\end{enumerate}
\end{enumerate}
\end{thmstar}

\begin{rmq}
Si  $(E,d)$ est une métrique séparable, alors $\mathcal{B}(E)$ est dénombrablement généré.
\end{rmq}

\begin{rmq}
Pour le point \textit{2.(a)}, il suffit en fait que la mesure soit extérieurement régulière sur les ouverts, et pour le point \textit{2.(b)}, il suffit qu'elle soit de plus intérieurement régulière sur les compacts.
\end{rmq}


\begin{thmstar}[Dérivée de Radon-Nikodym]
Soient $\mu$ et $\nu$ deux mesures $\sigma$-finies sur $(E,\mathcal{A})$. Si $\nu$ est absolument continue par rapport à $\mu$, alors il existe $f : E \mapsto \overline{\R}_+$ mesurable tel que $\nu=f\mu$.
\end{thmstar}

\begin{rmq}
Si $\nu$ est une mesure signée (en particulier finie), et $\mu$ une mesure $\sigma$-finie, on a l'équivalence entre les propositions suivantes :
\begin{itemize}
\item[(i)] $\nu \ll \mu$
\item[(ii)] Pour tout $\varepsilon >0$, il existe $\delta > 0$ tel que  $\forall A\in \mathcal{A}, \ \mu(A) \leq \delta \Rightarrow |\nu|(A) \leq \varepsilon$
\end{itemize}
L'hypothèse de finitude de $\nu$ est cruciale car elle donne l'intégrabilité de la dérivée de Radon-Nikodym par rapport à $\mu$.
\end{rmq}

\begin{thmstar}[Fubini-Tonelli]
Soient $\mu_1$ et $\mu_2$ deux mesures $\sigma$-finies sur $(E_1,\mathcal{E}_1)$ et $(E_2,\mathcal{E}_2)$. Si $f : E_1 \times E_2 \mapsto [0,+\infty]$ est mesurable, alors : 
\begin{enumerate}
\item $\displaystyle x\mapsto \int_{E_2} f(x,y) \mathrm{d}\mu_2(y)$ est mesurable pour $\mathcal{E}_1$, et $\displaystyle y\mapsto \int_{E_1} f(x,y) \mathrm{d}\mu_1(x)$ est mesurable pour $\mathcal{E}_2$. 
\item On a :
\[\int f(x,y)\mathrm{d}(\mu_1 \otimes \mu_2)(x,y)=\int_{E_1}\left(\int_{E_2} f(x,y) \mathrm{d}\mu_2(y)\right)\mathrm{d}\mu_1(x)=\int_{E_2}\left(\int_{E_1} f(x,y) \mathrm{d}\mu_1(x)\right)\mathrm{d}\mu_2(y) \]
\end{enumerate}
\end{thmstar}

\begin{rmq}
On dispose aussi de la version Fubini-Lebesgue dans le cas intégrable, qui aboutit aux mêmes conclusions, avec en plus que, pour $|f|$, les deux fonctions de \textit{1.} sont finies presque-partout.
\end{rmq}

\begin{rmq}
Les égalités des théorèmes de Fubini reposent entièrement sur le théorème de la classe monotone, d'où l'importance de l'hypothèse de $\sigma$-finitude.
\end{rmq}

\begin{corstar}[Intégration par parties]
Soient $f$ et $g$ sont deux fonctions mesurables, localement intégrables de $\R$ dans $\R$. On note, pour $x \in \R$ : \[ F(x) := \int_0^x f(t)\mathrm{d}t, \quad \text{et} \quad G(x) := \int_0^x g(t)\mathrm{d}t.\]
Alors, $F$ et $G$ sont absolument continues, dérivables presque partout, de dérivées presque partout égales respectivement à $f$ et $g$, et de plus, pour tout $a < b$ :
\[\int_a^b f(t)G(t)\mathrm{d}t = \Big(F(b)G(b)-F(a)G(a)\Big) - \int_a^b F(t)g(t)\mathrm{d}t\]
\end{corstar}

\begin{thmstar}[Changement de variable]
Soit $\varphi$ un $C^1$-difféomorphisme entre deux ouverts $U$ et $V$ de $\R^n$. On note $\varphi'(x)$ sa différentielle et $J_\varphi(x):=\det\left(\varphi'(x)\right)$ le jacobien de $\varphi$ au point $x\in U$. Alors :
\begin{enumerate}
\item Pour toute fonction $f\geq 0$ borélienne et tout borélien $B$ de $V$, on a :
\[\int_B f(y)\mathrm{d}y = \int_{\varphi^{-1}(B)}f(\varphi(x)) |J_\varphi(x)|\mathrm{d}x\]
\item Pour toute fonction borélienne $f$ sur $V$, la condition que $f$ soit intégrable sur $V$ est identique à la condition que la fonction $|J_\varphi(x)|f(\varphi(x))$ soit intégrable sur $U$, et dans ce cas, la formule du changement de variable ci-dessus est encore valide.
\end{enumerate}
\end{thmstar}


\subsection*{Outils importants}


\begin{corstar}[Unicité des mesures] Soient $\mu$ et $\nu$ deux mesures sur $(E,\mathcal{A})$ qui coïncident sur un $\pi$-système $\mathcal{C}$ tel que $\mathcal{A}=\sigma(\mathcal{C})$. Alors :
\begin{enumerate}
\item Si $\mu(E)=\nu(E) < +\infty$, alors $\mu = \nu$.
\item Si il existe une suite croissante $(A_n)_{n\in\N}$ d'éléments de $\mathcal{C}$ tels que $\displaystyle \bigcup_n A_n = E$, et que pour tout $n\in\N$, $\mu(A_n)=\nu(A_n)<+\infty$, alors $\mu = \nu$.
\end{enumerate}
\end{corstar}


\begin{lemmastar}[Fatou]
Soit $(f_n)_{n\in\N}$ une suite de fonctions mesurables positives. Alors :
\[\int \varliminf_n f_n \leq \varliminf_n \int f_n\]
\end{lemmastar}


\begin{propstar}[Continuité des intégrales]
Soit $t_0 \in T$  et $f : T \times E \mapsto \overline{\R} $. Si :
\begin{itemize}
\item[•] Pour tout $t\in T$, $x\mapsto f(t,x)$ est mesurable.
\item[•] Pour presque tout $x \in E$, $t\mapsto f(t,x)$ est continue en $t_0$.
\item[•] Il existe $g$ intégrable telle que pour tout $t\in T$, pour presque tout $x \in E$, on a $\left| f(t,x) \right| \leq g(x)$
\end{itemize}
Alors, $t\mapsto \displaystyle \int f(t,x)\mathrm{d}\mu(x)$ est continue en $t_0$.
\end{propstar}


\begin{propstar}[Dérivation des intégrales]
Soit $I$ un intervalle ouvert de $\R$, $t_0 \in I$, et $f:I \times E \mapsto \overline{\R}$. Si :
\begin{itemize}
\item[•] Pour tout $t\in I$, $x\mapsto f(t,x)$ est mesurable et intégrable.
\item[•] Pour presque tout $x \in E$, $t\mapsto f(t,x)$ est dérivable en $t_0$.
\item[•] Il existe $g$ intégrable telle que pour tout $t\in I$, pour presque tout $x \in E$, on a \[\left| f(t,x) - f(t_0,x) \right| \leq g(x) \left|t-t_0\right|\]
\end{itemize}
Alors, $t\mapsto \displaystyle \int f(t,x)\mathrm{d}\mu(x)$ est dérivable en $t_0$, de dérivée $\displaystyle \int \frac{\partial f}{\partial t} (t_0,x)\mathrm{d}\mu(x)$.
\end{propstar}


\begin{rmq}
On peut remplacer les deux dernières conditions par les suivantes, plus fortes, qui assurent alors la dérivabilité en tout point de l'intervalle :
\begin{itemize}
\item[•] Pour presque tout $x \in E$, $t\mapsto f(t,x)$ est dérivable sur tout $I$.
\item[•] Il existe $g$ intégrable tel que pour presque tout $x\in E$, pour tout $t\in I$, on a $\displaystyle \left| \frac{\partial f}{\partial t}(t,x) \right| \leq g(x)$.
\end{itemize}
\end{rmq}


\begin{propstar}[Mesure de Stieltjes]
Il y a une correspondance entre les fonctions croissantes continues à droite, et les mesures de Radon. Plus précisemment :
\begin{itemize}
\item[•] Si $\mu$ est une mesure de Radon sur $\R$, alors la fonction $F_{\mu}$ suivante est croissante, continue à droite.
$\displaystyle F_{\mu}(x) := \begin{cases} \mu(]0;x]) & \text{ si } x \geq 0  \\ -\mu(]x;0]) & \text{ si } x < 0 \end{cases}$
\item[•] Si $F : \R \mapsto \R$ est croissante, continue à droite, alors il existe une unique mesure de Radon $\mu$ telle que, pour tout $a<b \in \R$, $\mu(]a;b])=F(b)-F(a)$.
\end{itemize}
\end{propstar}

\begin{corstar}[Décomposition de Lebesgue]
Si $\mu$ et $\nu$ sont deux mesures $\sigma$-finies sur $(E,\mathcal{A})$, alors il existe une unique décomposition $\nu = \nu_a + \nu_s$ en deux mesures telles que $\nu_a$ est absolument continue par rapport à $\mu$, et $\nu_s$ est étrangère à $\mu$. 
\end{corstar}

\begin{propstar}[Points de Lebesgue]
Si $f \in L^1(\R^d,\mathcal{B}(\R^d),\lambda_d)$, alors presque tous les points de $\R^d$ sont des points de Lebesgue pour $f$.
\end{propstar}

\begin{corstar}
Si $\mu$ est une mesure de Radon absolument continue par rapport à la mesure de Lebesgue, alors sa dérivée de Radon-Nikodym $f$ est localement intégrable, et pour presque tout $x\in \R^d$ :
\[\lim\limits_{r \to 0}  \frac{\mu(B(x,r))}{\lambda_d(B(x,r))} = f(x)\]
\end{corstar}

\begin{rmq}
On peut en fait montrer que pour une mesure étrangère à $\lambda_d$, le taux d'accroissement ci-dessus tend vers 0. On en déduit que pour une mesure borélienne $\sigma$-finie quelconque, la limite de ce taux est presque-partout égal à la dérivée de Radon-Nikodym de la partie absolument continue de la décomposition de Lebesgue de cette mesure.
\end{rmq}

\begin{corstar}
L'intégrale d'une fonction $f \in L^1(\R,\mathcal{B}(\R),\lambda)$ contre la mesure de Lebesgue est presque partout dérivable, de dérivée $f$.
\end{corstar}

\begin{rmq}
La réciproque est fausse : une fonction borélienne dérivable presque partout n'est pas forcément égale à l'intégrale de sa dérivée. Par exemple l'escalier de Cantor est croissant continu sur $[0,1]$, de dérivée presque partout nulle, mais $F(1)-F(0)=1$. \\
En fait, si $f$ est croissante continue, par théorème de Stieltjes elle définie une mesure de Radon, et si la partie singulière dans sa décomposition de Lebesgue est nulle, i.e la mesure est absolument continue par rapport à la mesure de Lebesgue, alors on dit que $f$ est absolument continue. Sinon, il manque la contribution de la partie singulière.
\end{rmq}


\subsection*{Autres résultats}

\begin{rmq}
Il ya des raisons profondes au fait que l'on ne peut pas prendre l'ensemble des parties comme tribu pour faire de l'analyse. On peut par exemple montrer qu'il n'existe pas de mesure non triviale (non atomique) sur $(0,1)$ muni de la tribu des parties.
\end{rmq}

\begin{thmstar}
[Egorov] Si $\mu$ est une mesure finie, et $(f_n)_{n\in \N}$ est une suite de fonctions mesurables réelles convergeant $\mu$-presque-partout vers $f$ mesurable, alors pour tout $\varepsilon > 0$, il existe $A\in \mathcal{A}$ tel que $(f_n)_{n\in \N}$ converge uniformément vers $f$ sur $A$, et $\mu(E\setminus A) \leq \varepsilon $. 
\end{thmstar}

\begin{thmstar}
[Lusin] Soit $f : [a,b] \mapsto \R$ borélienne. Pour tout $\varepsilon>0$, il existe un compact $K\subset [a,b]$ avec $\lambda([a,b]\setminus K) \leq \varepsilon$, tel que la restriction de $f$ à $K$ est continue.
\end{thmstar}

\begin{rmq}
Le résultat ci dessus est en fait une équivalence, i.e une fonction est mesurable si et seulement si elle est continue sur un ensemble de mesure arbitrairement grande.
\end{rmq}

\begin{thmstar}[Décomposition de Jordan]

\end{thmstar}

\begin{rmq}
Version signée/complexe de représentation de Riesz.
\end{rmq}

\begin{thmstar}[Dualité]
Si $p$ et $q$ sont deux exposants conjugués finis, alors $L^q$ est le dual topologique de $L^p$.
\end{thmstar}



\newpage
\begin{center}
\section*{Probabilités} 
\end{center}

\subsection*{Contexte}
\begin{itemize}
\item[-] Une mesure de probabilité étant en particulier finie, on a dans ce cadre que les espaces $L^p$ sont emboités, i.e : $L^\infty \subseteq \dots \subseteq L^1$. Cela se traduit par le fait que si une variable aléatoire possède un moment d'ordre $k$, tous ses moments d'ordre inférieur sont également finis.
\item[-] Des variables indépendantes sont de covariance nulle, mais la réciproque est très fausse ! Par exemple en considérant une loi gaussienne et son produit par une v.a. de Rademacher, leur covariance est nulle mais elles ne sont pas indépendantes, sinon leurs valeurs absolues le seraient, et donc la gaussienne serait indépendante d'elle même, i.e. constante.
\item[-] À l'inverse, des variables a priori corrélées peuvent êtres indépendantes : si $U$ est une loi exponentielle et $V$ une loi uniforme sur $[0,1]$, alors $\sqrt{U}\cos(2\pi V)$ et $\sqrt{U}\sin(2\pi V)$ sont indépendantes et suivent chacune la loi $\mathcal{N}(0,1/2)$.
\end{itemize}

\subsection*{Méthode}
\begin{itemize}
\item[-] Utiliser les outils adaptés : pour étudier une somme de v.a. indépendantes on utilise la transformée de Fourier, pour étudier leur $\min$ on utilise la fonction de répartition, etc $\dots$
\item[-] Pour calculer la loi d'un couple $(X,Y)$ de v.a., on prend $f$ mesurable positive et on essaye d'écrire $\displaystyle E\left(f(X,Y)\right) = \int f(x,y) \mathrm{d}\mu(x,y)$, et alors le couple est de loi $\mu$.
\end{itemize}

\subsection*{Définitions et propriétés élémentaires}

\begin{definstar} Soit  $(\Omega, \mathcal{F}, P)$ un espace probabilisé, et $(E,\mathcal{E})$ un espace mesurable.
\begin{enumerate}
\item Si $X: \Omega \to E$ est mesurable, alors $X$ est appelée \textit{variable aléatoire} (v.a.) à valeurs dans $E$.
\item Si $X$ est une v.a. à valeurs dans E, on appelle loi de $X$ la mesure image de $P$ par $X$, notée $P_X$ et vérifiant : 
\[P_X(A) = P\left(X^{-1}(A)\right)=P\left(\left\{ \omega\in \Omega \setbar X(\omega)\in A \right\}\right) =P(X\in A).\]
\end{enumerate}
\end{definstar}

\begin{definstar}
Pour toute v.a.r $X$, on appelle \textit{fonction de répartition} de $X$ la donnée de $F_X :\R \to [0,1]$ définie par $F_X(t) = P(X\leq t) = P_X(]-\infty,t])$.
\end{definstar}

\begin{rmq}
$F_X$ est continue à droite, limitée à gauche (càdlàg), croissante, tend vers $0$ en $-\infty$, $1$ en $+\infty$, et caractérise $P_X$.
\end{rmq}

\begin{definstar}
Soit $X$ une v.a. à valeurs dans $\R^d$. On appelle \textit{fonction caractéristique} de $X$, notée $\Phi_X$, la fonction de $\R^d$ dans $\C$ définie par \[\Phi_X(\xi) := \int_{\R^d} e^{i\left<x,\xi\right>}\mathrm{d}P_X(x) = E\left(e^{i\left<X,\xi\right>}\right).\]
\end{definstar}

\begin{rmq}
$\Phi_X$ est en fait la transformée de Fourier de la loi $P_X$. C'est une fonction uniformément continue, dont le module est borné par $1$. $\Phi_X$ a autant de dérivées que $X$ a de moments finis.
\end{rmq}

\begin{rmq}
Si $X\sim \mathcal{N}(\mu,\sigma^2)$, alors $\Phi_X(\xi)=exp(i\xi\mu - \frac{\xi^2\sigma^2}{2})$.
\end{rmq}

\begin{definstar}
Si $X$ est une v.a. à valeurs dans $\N$, on appelle \textit{fonction génératrice} de $X$, la fonction $G_X : [0,1] \to \R^+$ définie par : \[G_X(t) := E(t^X) = \sum_{n=0}^{+\infty} t^nP(X=n).\]
\end{definstar}

\begin{rmq}
$G_X$ caractérise la loi de $X$, et détermine tous les moments de $X$ comme l'explique la proposition suivante.
\end{rmq}

\begin{propstar}
Soit $X$ une v.a. à valeurs dans $\N$, alors pour tout $k\geq 1$ :\[E\left(\prod_{i=0}^{k-1}(X-i)\right) = \lim_{t\to 1^-}G_X^{(k)}(t).\]
\end{propstar}

\begin{definstar}[Indépendance]~
\begin{itemize}
\item[-] Des événements $(A_i)_{i\in I}$  sont dits indépendants si pour toute partie finie $J$ de $I$, on a : \[P\Big(\bigcap_{j\in J}A_j\Big)=\prod_{j\in J}A_j\]
\item[-] Des tribus  $(\mathcal{A}_i)_{i\in I}$  sont dites indépendantes si pour toute famille $(A_i)_{i\in I}$ telle que $A_i\in \mathcal{A}_i$, les événements sont indépendants.
\item[-] Des variables aléatoires $(X_i)_{i\in I}$  à valeurs dans des espaces mesurables $(E_i,\mathcal{E}_i)$ sont dites indépendantes si la famille de tribus $(\sigma(X_i))_{i\in I}$ l'est.
\end{itemize}
\end{definstar}

\begin{rmq}
L'indépendance des $(X_i)_{i\in I}$ porte sur les tribus engendrées (sur $\Omega$) et non sur les
valeurs proprement dites de ces variables aléatoires. Par suite, si des $\Phi_i : (E_i,\mathcal{E}_i) \to (E'_i,\mathcal{E}'_i)$ sont mesurables, l'indépendance des $(X_i)_{i\in I}$ entraine celle des $(\Phi_i(X_i))_{i\in I}$.
\end{rmq}

\begin{rmq}
La vérification de l'indépendance des $(X_i)_{i\in I}$ se rammène à montrer que pour tout $J\subset I$ fini, pour toute famille $(A_j)_{j\in J}$ telle que $A_j\in \mathcal{E}_j$, on a $\displaystyle P\Big(\bigcap_{j\in J}(X_j\in A_j )\Big)=\prod_{j\in J}(X_j \in A_j)$.
\end{rmq}

\begin{propstar}
[Caractérisations de l'indépendance] Soit $(X_i)_{ 1 \leq i \leq n}$ une famille de variables aléatoires réelles, et $X:=(X_1,\dots,X_n)$. 
\begin{enumerate}
\item Si les $(X_i)_{ 1 \leq i \leq n}$ sont indépendants, et ont $(f_{X_i})_{1\leq i \leq n}$ comme densités respectives par rapport à la mesure de Lebesgue, alors $P_X \ll \lambda_n$ et a pour densité $f_X(x_1,\dots,x_n)=f_{X_1}(x_1)\dots f_{X_n}(x_n)$.
\item Réciproquement, si $P_X \ll \lambda_n$, de densité s'écrivant $f_X(x_1,\dots,x_n)=f_{X_1}(x_1)\dots f_{X_n}(x_n)$ où les $(f_i)_{1\leq i \leq n}$ sont des densités de probabilité (i.e. positives, d'intégrale valant $1$), alors les $(X_i)_{ 1 \leq i \leq n}$ sont indépendants, de densités respectives $(f_{X_i})_{1\leq i \leq n}$.
\end{enumerate}
\end{propstar}

\begin{corstar} Soit $(X_i)_{ 1 \leq i \leq n}$ des variables aléatoires réelles, les propriétés suivantes sont équivalentes :
\begin{enumerate}
\item  $(X_i)_{ 1 \leq i \leq n}$ est une famille de variables aléatoires indépendantes ; 
\item $P_X=\otimes_{i=1}^n P_{X_i}$
\item Pour toute famille $(f_i)_{1\leq i \leq n}$ de fonctions boréliennes positives, $\displaystyle E\left(\prod_{i=1}^n f_i(X_i)\right) = \prod_{i=1}^n E\left(f_i(X_i)\right)$
\item $\Phi_X=\otimes_{i=1}^n \Phi_{X_i}$
\end{enumerate}
\end{corstar}

\subsection*{Résultats principaux}

\begin{thmstar}
[Inégalité de Markov] Soit $X$ une variable aléatoire réelle presque surement positive, alors pour $\alpha>0$ : \[P(X \geq \alpha) \leq \frac{E(X)}{\alpha}\]
\end{thmstar}

\begin{thmstar}[Injectivité de la transformée de Fourier]
Soient $X_1$ et $X_2$ des variables aléatoires à valeurs dans $\R^d$. Si $\Phi_{X_1}=\Phi_{X_2}$, alors $P_{X_1}=P_{X_2}$.
\end{thmstar}

\begin{thmstar}
[Coalitions] Soit $(\mathcal{A}_i)_{i\in I}$ une famille de tribus engendrées par les $\pi$-systèmes $(C_i)_{i\in I}$. Alors ces tribus sont indépendantes si et seulement si les $\pi$-systèmes générateurs le sont. En particulier, si $(X_i)_{i\in I}$ est une famille de variables aléatoires indépendantes, et $(I_k)_{k\in K}$ une partition de $I$, alors les tribus $\big(\sigma\left(X_i,\ i\in I_k\right)\big)_{k\in K}$ sont indépendantes.
\end{thmstar}

\begin{thmstar}
[Loi faible des grands nombres] Soit $(X_i)_{i\in \N^*}$ une famille de variables aléatoires indépendantes de $L^2$, telles que $\lim\limits_{n\to +\infty} \frac{1}{n}\sum_{i=1}^n E(X_i) = \mu$ et $\sup_i V(X_i) = \sigma^2$. Alors : 
\begin{enumerate}
\item La moyenne empirique $\displaystyle \overline{X}_n := \frac{1}{n}\sum_{i=1}^n X_i$ converge dans $L^2$ vers la moyenne théorique $\mu$.
\item Pour $\varepsilon >0$, on a l'estimation suivante : \[P(|\overline{X}_n - E(\overline{X}_n)| \geq \varepsilon) \leq \frac{\sigma^2}{n\varepsilon^2}.\]
\end{enumerate}
\end{thmstar}

\begin{lemmastar}
[Borel-Cantelli] Soit $(A_n)_{n\geq 0}$ une suite d'évènements. On note $\limsup A_n := \displaystyle \bigcap_{n\geq 0} \bigcup_{k\geq n} A_k$, qui correspond à l'évènement ``être dans une infinité de $A_n$''. On a alors la dichotomie suivante :
\begin{enumerate}
\item Si $\displaystyle \sum_n P(A_n) < \infty$, alors $P(\limsup A_n)=0$, i.e. $\sum_n \mathds{1}_{A_n} < +\infty$ presque sûrement.
\item Si $\displaystyle \sum_n P(A_n) = \infty$ et que les $(A_n)_{n\geq 0}$ sont indépendants, alors $P(\limsup A_n)=1$.
\end{enumerate}
\end{lemmastar}

\begin{thmstar}
[Loi du 0-1] Si $(X_n)_{n\in\N}$ est une famille de variables aléatoires indépendantes, on note $\mathcal{F}_n^+ := \sigma(X_k, k\geq n)$ et $\displaystyle \mathcal{F}_\infty^+ := \bigcap_{n=1}^\infty \mathcal{F}_n^+$ la tribu asymptotique. Alors pour tout $A\in \mathcal{F}_\infty^+,  P(A)\in \{0,1\}$.
\end{thmstar}

\begin{rmq}
On en déduit qu'une variable aléatoire $ \mathcal{F}_\infty^+ $-mesurable est presque sûrement constante en considérant sa fonction de répartition. En particulier, les liminf et limsup d'une suite de v.a. indépendantes sont constantes presque sûrement, donc soit cette suite converge p.s. vers une constante, soit la limite n'existe p.s. jamais.
\end{rmq}

\begin{thmstar}
[Loi forte des grands nombres] Si $(X_n)_{n\in\N}$ est une suite de v.a. i.i.d. telle que $E(|X_1|)<\infty$, alors $P$ p.s. on a :
\[\frac{X_1 + \dots + X_n}{n} \to E(X_1) \]
\end{thmstar}

\begin{rmq}
Avec des résultats d'uniforme intégrabilité, on peut aussi obtenir la convergence au sens $L^1$ dans le théorème ci-dessus.
\end{rmq}

\begin{thmstar}
[Théorème central limite] Si $(X_n)_{n\in\N}$ est une suite de v.a. i.i.d. telle que $E(X_1^2)<\infty$, alors en notant $m := E(X_1)$ et $\sigma^2 := V(X_1)$, on a :
\[ \sqrt{n}(\overline{X}_n-m) \xrightarrow[]{\mathcal{L}} \mathcal{N}(0,\sigma^2) \]
\end{thmstar}

\subsection*{Outils importants}

\begin{lemmastar}
[Fekete] Si $(u_n)_{n\in\N}$ est une suite sous additive, i.e. $\forall n,m\in \N, \ u_{n+m} \leq u_n + u_m$, alors $\displaystyle (\frac{u_n}{n})_{n\in\N}$ converge, et on a l'égalité:  $\displaystyle \lim\limits_{n\to \infty} \frac{u_n}{n}=\inf_{n\geq 1} \frac{u_n}{n} \in \R \cup \{ -\infty\}$.
\end{lemmastar}

\begin{propstar}
[Formule de transfert] Soit $X$ une v.a. à valeurs dans $(E,\mathcal{E})$, et $f :E\to \overline{\R}$ une fonction mesurable telle que $f\geq0$ p.p. ou $E\big( \left|f(X)\right| \big) <\infty$, alors :
\[E(f(X))=\int_E f(x)\mathrm{d}P_X(x).\]
\end{propstar}

\begin{thmstar}
[Inégalité de Jensen] Soient $X\in L^1$, et $\Phi$ une fonction convexe sur un intervalle $I$ tel que $P(X\in I)=1$ et $E(|\Phi(X)|)<\infty$. Alors $\Phi(E(X)) \leq E(\Phi(X))$. Si $\Phi$ est de plus strictement convexe, alors il y a égalité si et seulement si $X$ est p.s constante.
\end{thmstar}

\begin{corstar}
[Inégalité de Bienaymé-Tchebychef] Si $X\in L^2$ est une v.a.r., alors pour tout $\varepsilon >0$ :
\[P(|X-E(X)| \geq \varepsilon) \leq \frac{V(X)}{\varepsilon^2}\]
\end{corstar}

\begin{propstar}
[Inégalité de Hoeffding]
Soient $(X_i)_{i\in \N^*}$ une famille de v.a. indépendantes à valeurs dans $[a,b]$. Alors pour tout $\epsilon > 0$ :
\[P( |\overline{X}_n - E(\overline{X}_n) | \geq \epsilon) \leq 2 \exp(-2\frac{n\varepsilon^2}{(b-a)^2})\]
\end{propstar}

\begin{thmstar}
[Lévy] Soit $(X_n)_{n\in \N^*}$ une suite de v.a. à valeurs dans $\R^d$, alors : $X_n \xrightarrow[]{\mathcal{L}} X_\infty$ si et seulement si $\Phi_{X_n} \to \Phi_{X_\infty}$ simplement.
\end{thmstar}
\subsection*{Autres résultats}

\begin{lemmastar}
Soit $I$ un intervalle de $\R$. Si $ \Phi :I \to \R$ est une fonction convexe, alors pour tout $x\in \mathring{I}$ :
\[\Phi(x) = \sup_{a,b \ | \ l_{a,b} \leq \Phi } l_{a,b}(x)\]
\end{lemmastar}

\begin{lemmastar}
Pour une v.a. à valeurs dans $\R^+$, $\displaystyle E(X)=\int_0^\infty P(X \geq x) \mathrm{d}x$, car $\displaystyle X=\int_0^\infty 1_{x\leq X} \mathrm{d}x$
\end{lemmastar} 


\newpage
\begin{center}
\section*{Martingales et processus aléatoires}
\end{center}

% Lire les lemmes écrits pas dans le poly de LeGall

% def esperance conditionelle
% Vision projection
% lemme : si z est y mesurable, il existe phi tq z = phi(y)  8.1.3
% version markov avec U non decreasing (car U(x) >= U(a) 1(x>=a) )
% Chernoff inequality (application de markov ci dessus avec U=exp )
% Rajouter partie dualité L^p L^q
% X et Y indep ssi E(g(X)f(Y))=E(g(X))E(f(Y)) (vérifier l'énoncé exact, ça utilise l'esperance conditionelle)
% Propriété de reflexion ?????? C'est quoi ce bordel ??????????????
% gaussienne dans la nature car c'est la loi d'entropie maximale ?
% Lebesgue est, à une constante près, l'unique mesure de Radon de R^d invariante par translation. La formule de Cameron-Martin donne en un certain sens un résultat du même type pour la mesure de Wiener, ce qui explique pourquoi cette dernière est décrite comme étant l'analogue de la mesure de Lebesgue en dimension infinie.

% Rajouter dans autre résultats de théorie de la mesure la tension des mesures finies sur un espace polonais.

%Rajouter la cv en loi et ses props (cf chap 8), en particulier "portmanteau"

% Schéma des implications de cv (version Trouvé et LeGall) + Scheffé (i.e. super théorème de cv dom)

% Commentaire que cv L1 et p.s sont de natures différentes, et p.s est plus naturelle pour les probas.

%Rajouter TDs de 1A et 2A why not

% Inégalité max de Kolmogorov, cv de séries aléatoires ?

% A rajouter du cours de JF Le Gall :


% TF DES LOIS USUELLES

% Portmanteau ? (Chap 8 prop 26 Trouvé)

% Interprétation loi et espérance conditionnelle : valeur moyenne de X quand B est réalisé ??

% Réfléchir aux interprétations pour avoir de manière intuitive que E( E(X | B) ) = E(X)

% Prop début cours 8.1.3

% 10.1.3 (voir lien avec 12.5 ?)

% 12.5

% 10.3.1 et globalement relire tout le cours.

% Scheffé

% Espace L^0 est complet

% pour les (sur/sous)-martingales, borné dans L1 => cv p.s
%
%\item calculs effectifs d'espérance et de loi conditionnelle 
%\item Props sur l'uniforme intégrabilité
%\item Super cv dominée
%\item Lemme de Scheffé

\newpage
\begin{center}
\section*{Systèmes dynamiques}
\end{center}

\end{document}
